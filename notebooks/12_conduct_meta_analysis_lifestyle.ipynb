{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "from functools import reduce\n",
    "import numpy as np\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define bonferroni p value\n",
    "\n",
    "20000 genes, 3 gene mask models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BONF_P = 0.05/(20000*3*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_meta_stats_helper(ser, ancestry, alpha=0.05):\n",
    "    effect_sizes = np.array([ser[f\"BETA_{a}\"] for a in ancestry if not pd.isnull(ser[f\"BETA_{a}\"])])\n",
    "    inverse_variances = np.array([(1/ser[f\"SE_{a}\"]**2) for a in ancestry if not pd.isnull(ser[f\"SE_{a}\"])])\n",
    "    assert len(effect_sizes)==len(inverse_variances)\n",
    "\n",
    "    if len(effect_sizes)==0:\n",
    "        return pd.NA, pd.NA, pd.NA, pd.NA, pd.NA, pd.NA, pd.NA\n",
    "\n",
    "    weighted_effect_size = np.sum(effect_sizes*inverse_variances)/np.sum(inverse_variances)\n",
    "    weighted_variance = 1/np.sum(inverse_variances)\n",
    "    weighted_se = np.sqrt(weighted_variance)\n",
    "\n",
    "    # Calculate the Z-score\n",
    "    z_score = weighted_effect_size / weighted_se\n",
    "    # Calculate the two-tailed p-value\n",
    "    p_value = 2 * norm.sf(abs(z_score)) #(1 - norm.cdf(abs(z_score)))\n",
    "\n",
    "    # Calculate critical value for confidence interval\n",
    "    z_critical = norm.ppf(1 - alpha / 2) \n",
    "\n",
    "    # Calculate confidence interval bounds\n",
    "    lower_ci = weighted_effect_size - z_critical * weighted_se\n",
    "    upper_ci = weighted_effect_size + z_critical * weighted_se\n",
    "\n",
    "    nsamples = sum([ser[f\"nsamples_{a}\"] for a in ancestry if not  pd.isnull(ser[f\"nsamples_{a}\"])])\n",
    "    return weighted_effect_size, weighted_se, lower_ci, upper_ci, z_score, p_value, nsamples\n",
    "\n",
    "\n",
    "def get_meta_stats(ser):\n",
    "    eur_ancestry = [\"eur_aou\", \"eur_ukb\"]\n",
    "    noneur_ancestry =  [\"afr_aou\", \"sas_aou\", \"eas_aou\", \"amr_aou\",  \"mid_aou\", \"afr_ukb\", \"sas_ukb\", \"eas_ukb\", \"amr_ukb\",] #mid_ukb\n",
    "    ees, ese, elci, ehci, ez_score, ep_value, esamples = get_meta_stats_helper(ser, eur_ancestry)\n",
    "    nees, nese, nelci, nehci, nez_score, nep_value, nesamples = get_meta_stats_helper(ser, noneur_ancestry)\n",
    "    es, se, lci, hci, z_score, p_value, nsamples = get_meta_stats_helper(ser, eur_ancestry+noneur_ancestry)\n",
    "    return pd.Series(\n",
    "        {\"gene\": ser.hgnc_gene, \"gene_mask\": ser.gene_mask, \n",
    "        \"beta\": es, \"se\": se, \"ci_low\": lci, \"ci_high\": hci, \"z_score\":z_score, \"p_value\": p_value, \"nsamples\": nsamples,\n",
    "        \"ebeta\": ees, \"ese\": ese, \"eci_low\": elci, \"eci_high\": ehci, \"ez_score\": ez_score, \"ep_value\": ep_value, \"esamples\": esamples,\n",
    "        \"nebeta\": nees, \"nese\": nese, \"neci_low\": nelci, \"neci_high\": nehci, \"nez_score\": nez_score, \"nep_value\": nep_value, \"nesamples\": nesamples,\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_meta_df(proj_dir, test_name, ancestry=[\"afr\", \"amr\", \"eas\", \"eur\", \"sas\", \"mid\"], biobank=[\"aou\", \"ukb\"]):\n",
    "    assoc_df = []\n",
    "    merge_columns = [\"hgnc_gene\", \"gene_mask\", \"ID\", \"lf\", \"ALLELE0\", \"ALLELE1\"]\n",
    "    stats_columns = [\"N\", \"BETA\", \"SE\", \"CHISQ\", \"LOG10P\", \"p_value\", \"nsamples\"]\n",
    "    for a in ancestry:\n",
    "        for b in biobank:\n",
    "            if (a==\"mid\") and (b==\"ukb\"):\n",
    "                continue\n",
    "            df = pd.read_csv(\n",
    "                os.path.join(proj_dir, f\"bmi_rint_{a}_{b}_{test_name}.tsv.gz\"), \n",
    "                sep=\"\\t\", usecols=merge_columns + stats_columns\n",
    "                )\n",
    "            df.columns =[f\"{c}_{a}_{b}\" if c not in merge_columns else c for c in df.columns]\n",
    "            assoc_df.append(df)\n",
    "\n",
    "    meta_df = reduce(lambda x,y: x.merge(\n",
    "        y, \n",
    "        on=merge_columns,\n",
    "        how=\"outer\"\n",
    "        ), assoc_df\n",
    "    )\n",
    "    return meta_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lf in [\"pa\", \"smoke\", \"alcohol\"]:\n",
    "    proj_dir = f\"../data/meta/processed/{lf}/\"\n",
    "    meta_df = create_meta_df(proj_dir, \"int\")\n",
    "    meta_res_df = meta_df.apply(get_meta_stats, axis=1)\n",
    "    meta_res_df.to_csv(\n",
    "        f\"../data/meta/results/{lf}/ivw_fixed/monolf_meta.tsv.gz\", \n",
    "        index=False, sep=\"\\t\"\n",
    "    )\n",
    "\n",
    "    sig_meta_res_df = meta_res_df.loc[\n",
    "        ((meta_res_df.ep_value<BONF_P)|(meta_res_df.nep_value<BONF_P))&\n",
    "        (meta_res_df.p_value<BONF_P)\n",
    "        ]\n",
    "    sig_meta_res_df.to_csv(\n",
    "        f\"../data/meta/results/{lf}/ivw_fixed/monolf_meta_sig.tsv\", \n",
    "        index=False, sep=\"\\t\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
