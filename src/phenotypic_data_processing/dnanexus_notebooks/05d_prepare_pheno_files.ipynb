{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import dxpy\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Get consensus data for phenotypes and covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_consensus(row):\n",
    "    values = [i for i in row.unique() if not pd.isnull(i)]\n",
    "    uniq_val = np.nan\n",
    "    if len(values)>1:\n",
    "        uniq_val = \"inconsistent\"\n",
    "    elif len(values) == 1:\n",
    "        uniq_val = values[0]\n",
    "    return uniq_val\n",
    "\n",
    "def get_mean(row):\n",
    "    return row.mean()\n",
    "\n",
    "def process_sample_info(df: pd.DataFrame, categorical_fields: dict, numerical_fields: dict):\n",
    "\n",
    "    # Make consensus column for categorical fields\n",
    "    for field, field_measures in categorical_fields.items():\n",
    "        df[field] = df.loc[:, field_measures].apply(get_consensus, axis=1)\n",
    "        df = df.drop(columns=field_measures)\n",
    "\n",
    "    # Get mean value for numerical fields\n",
    "    for field, field_measures in numerical_fields.items():\n",
    "        df[field] = df.loc[:, field_measures].apply(get_mean, axis=1)\n",
    "        df = df.drop(columns=field_measures)\n",
    "\n",
    "    # filter samples with nan values for all numerical fields\n",
    "    df = df.loc[~df.loc[:, numerical_fields.keys()].isna().all(axis=1)]\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "pheno_w_cov_file = f\"/mnt/project/notebooks/bmi/data/bmi_with_cov_raw.csv.gz\"\n",
    "\n",
    "numerical_fields = {\n",
    "    \"bmi\": [\"bmi0\", \"bmi1\", \"bmi2\", \"bmi3\"],\n",
    "    \"age\": [\"age_assessment0\", \"age_assessment1\", \"age_assessment2\", \"age_assessment3\"],\n",
    "    }\n",
    "\n",
    "categorical_fields = {\n",
    "    \"ethnic_background\": [\"ethnic_background0\", \"ethnic_background1\", \"ethnic_background2\"]\n",
    "    }\n",
    "\n",
    "dfs = []\n",
    "\n",
    "df = pd.read_csv(pheno_w_cov_file, dtype={\"sample_names\": str})\n",
    "processed_df = process_sample_info(df, categorical_fields, numerical_fields)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "processed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Add ancestry information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "ancestry_df = pd.read_csv(\n",
    "    \"/mnt/project/notebooks/ancestry_inference/data/ancestry_pred.csv.gz\", \n",
    "    dtype={\"sample_names\": str}\n",
    ")\n",
    "ancestry_dict = ancestry_df.loc[:, [\"sample_names\", \"ancestry_pred\"]].set_index(\"sample_names\").to_dict()[\"ancestry_pred\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "processed_df[\"ancestry_pred\"] = processed_df.sample_names.map(ancestry_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Add sample qc filter information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "sample_qc_df = pd.read_csv(\n",
    "    \"/mnt/project/notebooks/wes/sample_qc/data/flagged_samples.tsv\", \n",
    "    dtype={\"s\": str}, sep=\"\\t\", usecols=[\"s\", \"filters\"]\n",
    ").rename(columns={\"s\": \"sample_names\", \"filters\": \"sample_qc_filters\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "processed_df = processed_df.merge(sample_qc_df, on=\"sample_names\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "len(processed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Remove samples which\n",
    "- do not have exome data\n",
    "- failed qc filter\n",
    "- do not have BMI\n",
    "- do not have ancestry information\n",
    "- with >=10 third-degree relatives\n",
    "\n",
    "Note: Few missing covariate information apart from genetic sex can be handled by REGENIE. Therefore, age and genetic pcs were not checked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "filtered_df = processed_df.loc[\n",
    "    (processed_df.exome_release_batch.notna())&\n",
    "    (processed_df.sample_qc_filters.isna())&\n",
    "    (processed_df.bmi.notna())&\n",
    "    (processed_df.ancestry_pred.notna())&\n",
    "    (processed_df.genetic_kinship_to_other_participants!=\"Ten or more third-degree relatives identified\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "len(filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Add ICD info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "############\n",
    "# ICD tree #\n",
    "############\n",
    "class Node:\n",
    "    \"\"\"\n",
    "    Each ICD10 diagnosis is stored as a Node object\n",
    "    \"\"\"\n",
    "    def __init__(self, node_id, code, meaning, parent=None, child=None):\n",
    "        self.node = node_id\n",
    "        self.parent = parent\n",
    "        self.child = child\n",
    "        self.code, self.meaning = code, meaning\n",
    "        self.samples = set()\n",
    "\n",
    "    def add_child(self, child_node):\n",
    "        if self.child:\n",
    "            self.child.append(child_node)\n",
    "        else:\n",
    "            self.child = [child_node]\n",
    "        return\n",
    "\n",
    "    def add_parent(self, parent_node):\n",
    "        if not self.parent:\n",
    "            self.parent = parent_node\n",
    "        else:\n",
    "            assert self.parent == parent_node\n",
    "        return\n",
    "\n",
    "    def get_parent(self):\n",
    "        return self.parent\n",
    "\n",
    "    def get_child(self):\n",
    "        return self.child\n",
    "\n",
    "    def get_info(self):\n",
    "        return self.code, self.meaning\n",
    "    \n",
    "    def get_samples(self):\n",
    "        return self.samples\n",
    "    \n",
    "    def get_samples_number(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "class Tree:\n",
    "    def __init__(self, root_node, coding_df):\n",
    "        self.root = root_node\n",
    "        self.node_dict = {self.root.node : self.root}\n",
    "        self.coding_df = coding_df\n",
    "\n",
    "    def update_node_dict(self, node_id, node):\n",
    "        if node_id not in self.node_dict:\n",
    "            self.node_dict[node_id] = node\n",
    "        return\n",
    "\n",
    "    def create_node_from_df_helper(self, node_id):\n",
    "        c, m, ni, pi =  self.coding_df.loc[self.coding_df.node_id==node_id].values[0]\n",
    "        n = Node(ni, c, m)\n",
    "        return n, pi\n",
    "\n",
    "    def create_node_from_df(self, node_id):\n",
    "        if node_id in self.node_dict:\n",
    "            return self.node_dict[node_id]\n",
    "\n",
    "        # creating a node and providing parent information\n",
    "        mn, mnpi = self.create_node_from_df_helper(node_id)\n",
    "        # if parent is not present in the tree\n",
    "        if mnpi not in self.node_dict:\n",
    "            # create the parent node and get its parent\n",
    "            mnp = self.create_node_from_df(mnpi)\n",
    "            # add that parent info to the created node\n",
    "            mn.add_parent(mnp)\n",
    "        else:\n",
    "            mnp = self.node_dict[mnpi]\n",
    "            # add that parent info to the created node\n",
    "            mn.add_parent(mnp)\n",
    "\n",
    "        # update the node dict with the created node\n",
    "        self.update_node_dict(node_id, mn)\n",
    "        # add the created node as a child of the parent node\n",
    "        mnp.add_child(mn)\n",
    "        return mn\n",
    "\n",
    "    def print_node(self, curr_node, node_level, tree_file):\n",
    "        curr_node_info = curr_node.get_info()\n",
    "        if tree_file:\n",
    "            tree_file.write(f\"{'-' * node_level}{curr_node.node}\\t{curr_node_info[1]}\\n\")\n",
    "        else:\n",
    "            print(f\"{'-' * node_level}{curr_node.node}\\t{curr_node_info[1]}\\n\")\n",
    "        return\n",
    "\n",
    "    def print_tree(self, curr_node, tree_file=\"\", node_level=0, max_node_level=2):\n",
    "        if node_level>max_node_level:\n",
    "            return\n",
    "        \n",
    "        if curr_node:\n",
    "            self.print_node(curr_node, node_level, tree_file)\n",
    "\n",
    "            if curr_node.child:\n",
    "                for c in curr_node.child:\n",
    "                    self.print_tree(c, tree_file, node_level+1, max_node_level)\n",
    "        return\n",
    "    \n",
    "    def add_sample_info(self, node_id, samples):\n",
    "        curr_node = self.node_dict[node_id]\n",
    "        curr_node.samples = samples.union(curr_node.samples)\n",
    "        if curr_node.parent:\n",
    "            self.add_sample_info(curr_node.parent.node, samples)\n",
    "        return\n",
    "    \n",
    "def create_tree(icd_codes_df, icd_samples_df):\n",
    "    # create tree\n",
    "    # plant the tree\n",
    "    root_pheno = Node(0, \"0\", \"Root Phenotype\")\n",
    "    pheno_tree = Tree(root_pheno, icd_codes_df)\n",
    "    # fill the tree with leaves and branches - takes 6 secs\n",
    "    for ni in icd_codes_df.node_id:\n",
    "        pheno_tree.create_node_from_df(ni)\n",
    "    c2nodeid_dict = dict(zip(icd_codes_df.coding, icd_codes_df.node_id))\n",
    "    # add sample info\n",
    "    for icd_code, samples in zip(icd_samples_df.index, icd_samples_df.sample_names):\n",
    "        pheno_tree.add_sample_info(c2nodeid_dict[icd_code], set(samples.split(\"|\")))\n",
    "    return pheno_tree, root_pheno, c2nodeid_dict\n",
    "\n",
    "def create_icd_samples_file(icd_file):\n",
    "    icd_samples_df = pd.read_csv(icd_file)\n",
    "    icd_samples_df[\"icd\"] = icd_samples_df.icd.str.split(\"|\")\n",
    "    icd_samples_df = icd_samples_df.explode(\"icd\").groupby(\"icd\").agg(lambda x: \"|\".join(map(str,x)))\n",
    "    return icd_samples_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "icd_file = f\"/mnt/project/notebooks/bmi/data/icd_raw.csv.gz\"\n",
    "icd_codes_file = \"/mnt/project/fields/data/phenotype_processing/coding19.tsv\"\n",
    "\n",
    "icd_samples_df = create_icd_samples_file(icd_file)\n",
    "icd_codes_df = pd.read_csv(icd_codes_file, usecols=[\"coding\", \"meaning\", \"node_id\", \"parent_id\"], sep=\"\\t\")\n",
    "icd_codes_df[\"coding\"] = icd_codes_df.coding.str.replace(\" \", \"\")\n",
    "pheno_tree, root_pheno, c2nodeid_dict = create_tree(icd_codes_df, icd_samples_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "icd_code_map_dict = {\n",
    "    \"cvd\": {\"G45\": \"G45\", \"I20-I25\": \"BlockI20-I25\", \"I63\": \"I63\", \"I64\": \"I64\"}, # cvd\n",
    "    \"cad\": {\"I21\": \"I21\", \"I22\": \"I22\", \"I23\": \"I23\", \"I241\": \"I241\", \"I252\": \"I252\"}, # cad\n",
    "    \"ht\": {\"I10\": \"I10\", \"I15\": \"I15\"}, # ht\n",
    "    \"t1d\": {\"E10\": \"E10\"}, # t1d\n",
    "    \"t2d\": {\"E11\": \"E11\"}, #t2d\n",
    "    \"hf\": {\"I110\": \"I110\", \"I130\": \"I130\", \"I132\": \"I132\", \"I50\": \"I50\"},\n",
    "    \"af\": {\"I48\": \"I48\"},\n",
    "    \"pe\": {\"I26\": \"I26\"},\n",
    "    \"vt\": {\"I81\": \"I81\", \"I82\": \"I82\", \"I26\": \"I26\", \"O223\": \"O223\", \"O871\": \"O871\", \"O082\": \"O082\"},\n",
    "    \"avs\": {\"I350\": \"I350\", \"I352\": \"I352\"},\n",
    "    \"grd\": {\"K219\": \"K219\", \"K210\": \"K210\"},\n",
    "    \"cls\": {\"K80\": \"K80\"},\n",
    "    \"ccs\": {\"K81\": \"K81\"},\n",
    "    \"cd\": {\"K50\": \"K50\", \"M074\": \"M074\", \"M091\": \"M091\"},\n",
    "    \"nfld\": {\"K760\": \"K760\"},\n",
    "    \"koa\": {\"M170\": \"M170\", \"M171\": \"M171\", \"M179\": \"M179\"},\n",
    "    \"ob\": {\"E65\": \"E65\", \"E66\": \"E66\"},\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for disease, icd_dict in icd_code_map_dict.items():\n",
    "    comorbid_samples = set()\n",
    "    for icd, icdc in icd_dict.items():\n",
    "        icdc_node = pheno_tree.node_dict[c2nodeid_dict[icdc]]\n",
    "        comorbid_samples = comorbid_samples.union(icdc_node.get_samples())\n",
    "    filtered_df[disease] = filtered_df.sample_names.isin(comorbid_samples).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add lifestyle factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_consensus(row):\n",
    "    values = [i for i in row.unique() if not pd.isnull(i)]\n",
    "    uniq_val = np.nan\n",
    "    if len(values)>1:\n",
    "        uniq_val = \"inconsistent\"\n",
    "    elif len(values) == 1:\n",
    "        uniq_val = values[0]\n",
    "    return uniq_val\n",
    "\n",
    "def get_mean(row):\n",
    "    return row.mean()\n",
    "\n",
    "def process_sample_info(df, categorical_fields, numerical_fields):\n",
    "    # Make consensus column for categorical fields\n",
    "    for field in categorical_fields:\n",
    "        field_columns = df.loc[:, df.columns.str.startswith(field)].columns.values\n",
    "        df[field] = df.loc[:, field_columns].apply(get_consensus, axis=1)\n",
    "        df = df.drop(columns=field_columns)\n",
    "\n",
    "    # Get mean value for numerical fields\n",
    "    for field in numerical_fields:\n",
    "        field_columns = df.loc[:, df.columns.str.startswith(field)].columns.values\n",
    "        df_fields = df.loc[:, field_columns].replace([\"Less than one\", \"Less than an hour a day\", \"Do not know\", \"Prefer not to answer\"], [0, 0, np.nan, np.nan]).astype(float)\n",
    "        df[field] = df_fields.apply(get_mean, axis=1)\n",
    "        df = df.drop(columns=field_columns)    \n",
    "    return df.loc[:, [\"sample_names\"] + numerical_fields + categorical_fields]\n",
    "\n",
    "def high_dir(df, field, thresh):\n",
    "    return (df[field]>thresh).astype(int)\n",
    "\n",
    "def low_dir(df, field, thresh):\n",
    "    return (df[field]<thresh).astype(int)\n",
    "\n",
    "\n",
    "def binarize_lifestyle(lf_df, cat_encoding_dict, numerical_fields_w_dir_dict, numerical_field_range_dict, combine_field_dict):\n",
    "    df = lf_df.copy()\n",
    "    for field, pattern in cat_encoding_dict.items():\n",
    "        df[field] = df[field].str.fullmatch(rf\"{pattern}\", na=False).astype(int)\n",
    "\n",
    "    # encode all non numeric values as numeric ones\n",
    "    df.loc[:, numerical_fields_w_dir_dict.keys()] = df.loc[:, numerical_fields_w_dir_dict.keys()].replace([\"Less than an hour a day\", \"Less than one\", \"Do not know\", \"Prefer not to answer\", \"inconsistent\"], [0, 0, np.nan, np.nan, np.nan]).astype(float)\n",
    "    q_dir = {\"high\": 0.95, \"low\": 0.05}\n",
    "    f_dir = {\"high\": high_dir, \"low\": low_dir}\n",
    "    for num_field, num_dir in numerical_fields_w_dir_dict.items():\n",
    "        num_field_quantile_thresh = df[num_field].quantile(q=q_dir[num_dir])\n",
    "        df[num_field] = f_dir[num_dir](df, num_field, num_field_quantile_thresh) # (df[num_field]>num_field_quantile_thresh).astype(int)\n",
    "    \n",
    "    # encode all wihtin normal range fields\n",
    "    df.loc[:, numerical_field_range_dict.keys()] = df.loc[:, numerical_field_range_dict.keys()].replace([\"Less than an hour a day\", \"Less than one\", \"Do not know\", \"Prefer not to answer\", \"inconsistent\"], [0, 0, np.nan, np.nan, np.nan]).astype(float)\n",
    "    for range_field, range_ in numerical_field_range_dict.items():\n",
    "        df[range_field] = (~df[range_field].between(*range_)).astype(int)\n",
    "\n",
    "    # combine fields to one numeric value\n",
    "    # smoke\n",
    "    df[\"smoke\"] = (df.loc[:, combine_field_dict[\"smoke\"]]==1).any(axis=1).astype(int)\n",
    "    # sedentary lifestyle\n",
    "    df[\"sedentary\"] = (df.loc[:, combine_field_dict[\"sedentary\"]]==1).any(axis=1).astype(int)\n",
    "    # diet\n",
    "    df[\"diet\"] = (((df.loc[:, combine_field_dict[\"diet\"][0]]).sum(axis=1)>1)|((df.loc[:, combine_field_dict[\"diet\"][1]]).sum(axis=1)>0)).astype(int)\n",
    "    return df.loc[:, [\"sample_names\", \"met\", \"alcohol\", \"smoke\", \"sleep\", \"sedentary\", \"diet\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "binary_fields = [\"met\"]\n",
    "\n",
    "integer_fields = [\n",
    "    \"sleep\", \"tv\", \"computer\", \n",
    "    \"cookedvegetable\", \"salad\", \"freshfruit\", \"driedfruit\"\n",
    "    ]\n",
    "\n",
    "categorical_fields = [\n",
    "    \"alcohol\", \"smokecurr\", \"smokepast\", \"oilyfish\", \"nonoilyfish\", \n",
    "    \"procmeat\", \"poultry\", \"beef\", \"mutton\", \"pork\"\n",
    "]\n",
    "\n",
    "lf_df = pd.read_csv(f\"/mnt/project/notebooks/bmi/data/lifestyle_raw.csv.gz\")\n",
    "lf_df = process_sample_info(lf_df, categorical_fields + binary_fields, integer_fields)\n",
    "\n",
    "cat_encoding_dict = {\n",
    "    \"alcohol\": \"Daily or almost daily\",\n",
    "    \"smokecurr\": \"Yes, on most or all days\",\n",
    "    \"smokepast\": \"Yes, on most or all days\",\n",
    "    \"met\": \"No\",\n",
    "    \"oilyfish\": \"Never|Less than once a week\",\n",
    "    \"nonoilyfish\": \"Never|Less than once a week\",\n",
    "    \"procmeat\": \"5-6 times a week|Once or more daily\",\n",
    "    \"beef\": \"5-6 times a week|Once or more daily\",\n",
    "    \"mutton\": \"5-6 times a week|Once or more daily\",\n",
    "    \"pork\": \"5-6 times a week|Once or more daily\"\n",
    "}\n",
    "\n",
    "numerical_fields_w_dir_dict = {\n",
    "    \"tv\": \"high\",\n",
    "    \"computer\": \"high\",\n",
    "    \"cookedvegetable\": \"low\",\n",
    "    \"salad\": \"low\",\n",
    "    \"freshfruit\": \"low\",\n",
    "    \"driedfruit\": \"low\"\n",
    "}\n",
    "\n",
    "numerical_field_range_dict = {\n",
    "    \"sleep\": (6, 8)\n",
    "}\n",
    "\n",
    "combine_field_dict = {\n",
    "    \"smoke\": [\"smokecurr\", \"smokepast\"],\n",
    "    \"sedentary\": [\"tv\", \"computer\"],\n",
    "    \"diet\": [[\"cookedvegetable\", \"salad\", \"freshfruit\", \"driedfruit\", \"oilyfish\", \"nonoilyfish\"], [\"procmeat\", \"beef\", \"mutton\", \"pork\"]]\n",
    "}\n",
    "\n",
    "binarized_df = binarize_lifestyle(lf_df, cat_encoding_dict, numerical_fields_w_dir_dict, numerical_field_range_dict, combine_field_dict)\n",
    "binarized_df = binarized_df.rename(columns={\"met\": \"pa\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "binarized_df[\"sample_names\"] = binarized_df.sample_names.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "filtered_df = filtered_df.merge(binarized_df, on=\"sample_names\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload phenotype file to project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def upload_file_to_project(filename, proj_dir):\n",
    "    dxpy.upload_local_file(filename, folder=proj_dir, parents=True)\n",
    "    print(f\"*********{filename} uploaded!!*********\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "proj_dir = f\"/notebooks/bmi/data/\"\n",
    "filename = f\"pheno.csv.gz\"\n",
    "filtered_df.to_csv(filename, index=False)\n",
    "upload_file_to_project(filename, proj_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
