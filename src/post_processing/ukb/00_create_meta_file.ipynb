{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"tags":[],"trusted":true},"outputs":[],"source":["import os\n","import pandas as pd\n","from functools import reduce\n","import dxpy"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[],"trusted":true},"outputs":[],"source":["def read_chrm_regenie_file(filedir, anc, lf, chrm, pheno):\n","    filepath = os.path.join(filedir, anc, chrm, f\"output{lf}\", f\"bmi_quant_{pheno}.regenie\")\n","    df = pd.read_csv(filepath,  sep=\"\\s\", comment=\"#\", engine=\"python\")\n","    return df\n","\n","def read_monogenic_file(filedir, anc, pheno):\n","    mono_df = []\n","    for chrm in [i for i in range(1, 23)]:\n","        df = read_chrm_regenie_file(filedir, anc, \"\", f\"chrm{chrm}\", pheno)\n","        # filter for ultrarare\n","        df = df.loc[df.ID.str.endswith(\"0.001\")]\n","        df[\"p_value\"] = 10**(-df.LOG10P)\n","        mono_df.append(df)\n","    mono_df = pd.concat(mono_df)\n","    mono_df.columns = [f\"{c}_{anc}\" if c!=\"ID\" else c for c in mono_df.columns]\n","    return mono_df\n","\n","def read_mono_lf_file(filedir, anc, pheno, lf):\n","    mono_df = []\n","    for chrm in [i for i in range(1, 23)]:\n","        df = read_chrm_regenie_file(filedir, anc, lf, f\"chrm{chrm}\", pheno)\n","        # filter for ultrarare\n","        df = df.loc[df.ID.str.endswith(\"0.001\")]\n","        df[\"p_value\"] = 10**(-df.LOG10P)\n","        mono_df.append(df)\n","    mono_df = pd.concat(mono_df)\n","    mono_df.columns = [f\"{c}_{anc}\" if c!=\"ID\" else c for c in mono_df.columns]\n","    return mono_df"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[],"trusted":true},"outputs":[],"source":["monogenic_dir = f\"/mnt/project/notebooks/regenie/data/step2/monogenic\"\n","mono_lf_dir = f\"/mnt/project/notebooks/regenie/data/step2/mono_lf\"\n","pheno_dir = f\"/mnt/project/notebooks/regenie/data/\"\n","ancestry = [\"british\", \"nonbritish\"]\n","pheno = [\"bmi\", \"hba1c_df\", \"hdl\", \"ldl_sf\"]\n","lifestyle = [\"pa\", \"alcohol\", \"smoke\"]\n","\n","gene_burden_df = pd.read_csv(\"/mnt/project/notebooks/regenie/data/gene_burden.csv.gz\")\n","lifestyle_df = pd.read_csv(\"/mnt/project/notebooks/regenie/data/pheno.csv.gz\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[],"trusted":true},"outputs":[],"source":["def create_gene_burden_table_helper(burden_df, annotations, maf, lf_samples_df):\n","    masked_burden_df = burden_df.loc[(burden_df.annotation.isin(annotations))&(burden_df.maf<=maf)].groupby(\"gene\").agg({\"samples\": lambda x: set(\",\".join(x).split(\",\"))}).reset_index()\n","    masked_burden_df = pd.concat([masked_burden_df, lf_samples_df])\n","    return masked_burden_df\n","\n","def create_gene_burden_tables(burden_df, maf, lf_samples_df):\n","    masks = [\"PTV\", \"PTV_Missense_strict\", \"PTV_Missense_lenient\"]\n","    annot_terms = [[\"lof\"], [\"lof\", \"missense_strict\"], [\"lof\", \"missense_strict\", \"missense_lenient\"]]\n","    gene_burden_dict = dict(zip(masks, [create_gene_burden_table_helper(burden_df, at, maf, lf_samples_df) for at in annot_terms]))\n","    return gene_burden_dict\n","\n","\n","def get_nsamples_helper(combos, genotype_df, cohort_samples):\n","    if len(set(combos).intersection(set(genotype_df.gene.values))) == len(combos):\n","        samples_per_gene = genotype_df.loc[genotype_df.gene.isin(combos)].samples.values\n","        samples_per_combo = reduce(lambda a,b: set(a).intersection(set(b)), samples_per_gene)\n","        samples_per_combo = cohort_samples.intersection(samples_per_combo)\n","    else:\n","        samples_per_combo = []\n","    return samples_per_combo\n","\n","def get_nsamples(ser, gene_burden_dict, pop_samples):\n","    gene = ser.ID.split(\".\")[0]\n","    mask = ser.ID.split(\".\")[1]\n","    gene_samples_df = gene_burden_dict[mask]\n","    \n","    combos = [gene]\n","    if \"lf\" in ser.index:\n","        lf = ser.lf\n","        combos.append(lf)\n","    samples = get_nsamples_helper(combos, gene_samples_df, pop_samples)\n","    return len(samples)\n","\n","def get_lifestyle_burden(lifestyle_df, lifestyles):\n","    lifestyle_long = lifestyle_df.loc[:, [\"sample_names\"]+lifestyle].melt(id_vars=['sample_names'], value_vars=lifestyles)\n","    lifestyle_long[\"sample_names\"] = lifestyle_long.sample_names.astype(str)\n","    lifestyle_long = lifestyle_long.loc[lifestyle_long.value==1]\n","    lifestyle_long = lifestyle_long.groupby(\"variable\").agg({\"sample_names\": lambda x: set(x)}).reset_index()\n","    lifestyle_long = lifestyle_long.rename(columns={\"variable\": \"gene\", \"sample_names\": \"samples\"})\n","    return lifestyle_long\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[],"trusted":true},"outputs":[],"source":["lifestyle_burden = get_lifestyle_burden(lifestyle_df, lifestyle)\n","gene_burden_dict = create_gene_burden_tables(gene_burden_df, 0.001, lifestyle_burden)"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[],"trusted":true},"outputs":[],"source":["bmi_mono_df = []\n","for a in ancestry:\n","    mono_df = read_monogenic_file(monogenic_dir, a, pheno[0]).reset_index(drop=True)\n","    pheno_df = pd.read_csv(os.path.join(pheno_dir, f\"{a}_phenotype.tsv.gz\"), sep=\"\\t\")\n","    pop_samples = set(pheno_df.IID.astype(str))\n","    mono_df[f\"nsamples_{a}\"] = mono_df.apply(get_nsamples, axis=1, args=(gene_burden_dict, pop_samples))\n","    bmi_mono_df.append(mono_df)"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[],"trusted":true},"outputs":[],"source":["bmi_mono_df = reduce(lambda x,y: x.merge(y, on=\"ID\", how=\"outer\"), bmi_mono_df)"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[],"trusted":true},"outputs":[],"source":["bmi_mono_df.to_csv(\"./bmi_ukb_meta_w_samples.csv.gz\", index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[],"trusted":true},"outputs":[],"source":["bmi_mono_lf_df = []\n","for a in ancestry:\n","    print(a)\n","    mld = pd.DataFrame()\n","    for lf in lifestyle:\n","        print(lf)\n","        mono_lf_df = read_mono_lf_file(mono_lf_dir, a, pheno[0], lf).reset_index(drop=True)\n","        mono_lf_df[\"lf\"] = lf\n","        pheno_df = pd.read_csv(os.path.join(pheno_dir, f\"{a}_phenotype.tsv.gz\"), sep=\"\\t\")\n","        pop_samples = set(pheno_df.IID.astype(str))\n","        mono_lf_df[f\"nsamples_{a}\"] = mono_lf_df.apply(get_nsamples, axis=1, args=(gene_burden_dict, pop_samples))\n","        mld = pd.concat([mono_lf_df, mld])\n","    mld[\"TEST\"] = mld[f\"TEST_{a}\"]\n","    bmi_mono_lf_df.append(mld)"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[],"trusted":true},"outputs":[],"source":["bmi_mono_lf_df = reduce(lambda x,y: x.merge(y, on=[\"ID\", \"lf\", \"TEST\"], how=\"outer\"), bmi_mono_lf_df)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[],"trusted":true},"outputs":[],"source":["bmi_mono_lf_df_short = bmi_mono_lf_df.loc[bmi_mono_lf_df.ID.str.endswith(\"0.001\")]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[],"trusted":true},"outputs":[],"source":["len(bmi_mono_lf_df), len(bmi_mono_lf_df_short)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[],"trusted":true},"outputs":[],"source":["bmi_mono_lf_df_short.to_csv(\"./bmi_lf_ukb_meta_w_samples.csv.gz\", index=False)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[],"trusted":true},"outputs":[],"source":["def upload_file_to_project(filename, proj_dir):\n","    dxpy.upload_local_file(filename, folder=proj_dir, parents=True)\n","    print(f\"*********{filename} uploaded!!*********\")\n","    os.remove(filename)\n","    return"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[],"trusted":true},"outputs":[],"source":["proj_dir=\"/notebooks/regenie/data/meta/\"\n","filename=\"bmi_lf_ukb_meta_w_samples.csv.gz\"\n","upload_file_to_project(filename, proj_dir)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"}},"nbformat":4,"nbformat_minor":4}
