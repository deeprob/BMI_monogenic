{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import dxpy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create reference and ukb data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "ref_df = pd.read_csv(\"/mnt/project/notebooks/ancestry_inference/data/ref_pca.csv.gz\")\n",
    "geno_df = pd.read_csv(\"/mnt/project/notebooks/ancestry_inference/data/geno_pca.csv.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_training_data(ref_df, npca=16):\n",
    "    # first combine nfe and fin\n",
    "    train_df = ref_df.copy()\n",
    "    train_df = train_df.loc[train_df.ancestry_pred!=\"oth\"]\n",
    "    label_mappings = {\n",
    "        \"afr\": \"afr\", \"amr\": \"amr\", \"eas\": \"eas\",  \"mid\": \"mid\",\n",
    "        \"fin\": \"eur\", \"nfe\": \"eur\", \"sas\": \"sas\", \"oth\": \"oth\"\n",
    "    }\n",
    "    train_df.loc[:, \"label\"] = train_df.ancestry_pred.map(label_mappings)\n",
    "    X_train, y_train = train_df.loc[:, [f\"pca_{i}\" for i in range(1, npca+1)]], train_df.label\n",
    "    return X_train.values, y_train.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X_train, y_train = get_training_data(ref_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X_test = geno_df.loc[:, [f\"pca_{i}\" for i in range(1,17)]].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Step 4: Define the pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# Step 5: Define the parameter grid for different PCA feature counts\n",
    "param_grid = {\n",
    "    'classifier__n_estimators': [100, 200],\n",
    "    'classifier__max_depth': [None, 10]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Perform GridSearchCV\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy', verbose=0)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and cross-validation score\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best Cross-Validation Score: {grid_search.best_score_:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "best_model = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "best_model['classifier'].classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Predict the probabilities for the 6 ancestries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "predicted_prob = best_model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "predicted_prob_df = pd.DataFrame(data=predicted_prob, index=geno_df.s, columns=best_model['classifier'].classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assign ancestries based on predicted prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_ancestry(ser):\n",
    "    most_likely_anc = ser.loc[ser>0.75].index\n",
    "    if len(most_likely_anc)>0:\n",
    "        assert len(most_likely_anc)==1\n",
    "        most_likely_anc = most_likely_anc[0]\n",
    "    else:\n",
    "        most_likely_anc=\"oth\"\n",
    "    return most_likely_anc\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "predicted_prob_df[\"ancestry_pred\"] = predicted_prob_df.apply(get_ancestry, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check consistency with self-reported ehtnicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "pheno_df = pd.read_csv(\"/mnt/project/notebooks/regenie/data/pheno.csv.gz\", usecols=[\"sample_names\", \"ethnic_background\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "pheno_df = pheno_df.merge(predicted_prob_df, left_on=\"sample_names\", right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "len(pheno_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Creating a pivot table to count overlaps of ethnic background vs ancestry\n",
    "pivot_table = pd.pivot_table(pheno_df, \n",
    "                             index='ethnic_background', \n",
    "                             columns='ancestry_pred', \n",
    "                             aggfunc='size', \n",
    "                             fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "pivot_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "most_likely_ancestry_dict = {\n",
    "    \"African\": \"afr\",\n",
    "    \"Bangladeshi\": \"sas\",\n",
    "    \"British\": \"eur\",\n",
    "    \"Chinese\": \"eas\",\n",
    "    \"Indian\": \"sas\",\n",
    "    \"Irish\": \"eur\",\n",
    "    \"Pakistani\": \"sas\",\n",
    "    \"White\": \"eur\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "consistency_df = pheno_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "consistency_df = consistency_df.loc[consistency_df.ethnic_background.isin(set(most_likely_ancestry_dict.keys()))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "consistency_df[\"most_likely_ancestry\"] = consistency_df.ethnic_background.map(most_likely_ancestry_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "accuracy_score(consistency_df.most_likely_ancestry, consistency_df.ancestry_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class_report = classification_report(consistency_df.most_likely_ancestry, consistency_df.ancestry_pred, output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class_resport_df = pd.DataFrame(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def upload_file_to_project(filename, proj_dir):\n",
    "    dxpy.upload_local_file(filename, folder=proj_dir, parents=True)\n",
    "    print(f\"*********{filename} uploaded!!*********\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class_resport_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "proj_dir = f\"/notebooks/ancestry_inference/data/\"\n",
    "filename = \"consistency_report.csv\"\n",
    "class_resport_df.to_csv(filename)\n",
    "upload_file_to_project(filename, proj_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "proj_dir = f\"/notebooks/ancestry_inference/data/\"\n",
    "filename = \"final_run_ancestry_pivot.csv\"\n",
    "pivot_table.to_csv(filename)\n",
    "upload_file_to_project(filename, proj_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "proj_dir = f\"/notebooks/ancestry_inference/data/\"\n",
    "filename = \"ancestry_pred.csv.gz\"\n",
    "pheno_df.to_csv(filename, index=False)\n",
    "upload_file_to_project(filename, proj_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
