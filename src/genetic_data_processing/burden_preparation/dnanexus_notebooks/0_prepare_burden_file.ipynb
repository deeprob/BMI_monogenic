{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import dxpy\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def annotate_variant_consequence(ser):\n",
    "    annot = pd.NA\n",
    "    consequence =  set(ser.consequence.split(\";\"))\n",
    "    ptv_terms = set([\"frameshift_variant\", \"stop_gained\", \"splice_acceptor_variant\", \"splice_donor_variant\"])\n",
    "    if len(ptv_terms.intersection(consequence))>0:\n",
    "        annot = \"lof\"\n",
    "    elif \"missense_variant\" in consequence:\n",
    "        if ser.del_score==9:\n",
    "            annot = \"missense_strict\"\n",
    "        elif ser.del_score>6:\n",
    "            annot = \"missense_lenient\"\n",
    "    return annot\n",
    "\n",
    "def keep_most_del(vals):\n",
    "    vals = set(vals)\n",
    "    if \"lof\" in vals:\n",
    "        return \"lof\"\n",
    "    elif \"missense_strict\" in vals:\n",
    "        return \"missense_strict\"\n",
    "    return list(vals)[0]\n",
    "\n",
    "def create_helper_files(chr_exome_file):\n",
    "    df = pd.read_csv(chr_exome_file, sep=\"\\t\", dtype={\n",
    "        \"locus\": str, \"alleles\": str, \"gene\": str, \"transcript\": str, \"consequence\": str, \"biotype\": str, \"loftee\": str,\n",
    "        \"lof\": bool, \"splice_lof\": bool, \"missense\": bool,  \"del_score\": float, \"maf\": float, \"mac\": float, \"call_rate\": float,\n",
    "        \"p_value_hwe\": float, \"min_rd\": float, \"samples\": str, \"hetz_samples\": str, \"homo_samples\": str\n",
    "    })\n",
    "    # get the variants in correct format\n",
    "    df[\"variants\"] = df.locus.str.lstrip(\"chr\") + \":\" + df.alleles.str.replace(\"_\", \":\")\n",
    "    # add lof and missense annotations\n",
    "    df[\"annotation\"] = df.apply(annotate_variant_consequence, axis=1)\n",
    "    # filter by annotations, biotype, and call rate\n",
    "    df = df.loc[\n",
    "        (df.annotation.isin([\"lof\", \"missense_strict\", \"missense_lenient\"]))&\n",
    "        (df.biotype==\"protein_coding\")&\n",
    "        (df.samples.notna()) # there are some variants which do not have samples because sqc was applied after vqc\n",
    "    ]\n",
    "    return df\n",
    "\n",
    "def create_burden_df(chrm_dir):\n",
    "    chrms = [i for i in range(1, 23)]\n",
    "    dfs = []\n",
    "    for chrm in chrms:\n",
    "        chr_df = create_helper_files(f\"{chrm_dir}/chr{chrm}.tsv.gz\")\n",
    "        dfs.append(chr_df)\n",
    "    df = pd.concat(dfs)\n",
    "    return df\n",
    "\n",
    "def upload_file_to_project(filename, proj_dir):\n",
    "    dxpy.upload_local_file(filename, folder=proj_dir, parents=True)\n",
    "    print(f\"*********{filename} uploaded!!*********\")\n",
    "    os.remove(filename)\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create and save burden df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "burden_df = create_burden_df(\"/mnt/project/notebooks/wes/variant_annot/data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "proj_dir = \"/notebooks/wes/burden_preparation/data/\"\n",
    "filename = \"ukb_burden.tsv.gz\"\n",
    "burden_df.to_csv(filename, sep='\\t', index=False, header=True)\n",
    "upload_file_to_project(filename, proj_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save unique locus and alleles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "burden_df = pd.read_csv(\"/mnt/project/notebooks/wes/burden_preparation/data/ukb_burden.tsv.gz\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "proj_dir = \"/notebooks/wes/burden_preparation/data/\"\n",
    "filename = \"ukb_ptv_locus.tsv\"\n",
    "burden_df.loc[:, [\"locus\", \"alleles\"]].drop_duplicates().to_csv(filename, sep='\\t', index=False, header=True)\n",
    "upload_file_to_project(filename, proj_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "burden_df.loc[:, [\"locus\", \"alleles\"]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
