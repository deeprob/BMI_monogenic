{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import hail as hl\n",
    "import os\n",
    "import time\n",
    "import dxpy\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "\n",
    "# Had to set the configuration to navigate RDD partition error\n",
    "# Build spark\n",
    "builder = (\n",
    "    SparkSession\n",
    "    .builder\n",
    "    .appName(\"HailApplication\")  # Set a meaningful application name\n",
    "    .config(\"spark.driver.memory\", \"16g\")  # Set driver memory (e.g., 8 GB)\n",
    "    .config(\"spark.executor.memory\", \"24g\")  # Set executor memory (e.g., 16 GB)\n",
    "    .config(\"spark.executor.cores\", \"12\")  # Optional: Set number of cores per executor \n",
    "    .enableHiveSupport()\n",
    ")\n",
    "spark = builder.getOrCreate()\n",
    "\n",
    "hl.init(sc=spark.sparkContext, idempotent=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def save_in_hail_format(hail_obj, db_name, hail_obj_name, rerun):\n",
    "    # Create DB if it does not exist\n",
    "    stmt = f\"CREATE DATABASE IF NOT EXISTS {db_name} LOCATION 'dnax://'\"\n",
    "    spark.sql(stmt).show()\n",
    "    # Find database ID of newly created database using dxpy method\n",
    "    db_uri = dxpy.find_one_data_object(name=f\"{db_name}\".lower(), classname=\"database\")['id']\n",
    "    # Write hail object\n",
    "    url = f\"dnax://{db_uri}/{hail_obj_name}\"\n",
    "    if rerun:\n",
    "        hail_obj.write(url, overwrite=True)\n",
    "    return url\n",
    "\n",
    "def get_url(db_name, hail_obj_name):\n",
    "    # Find database ID of newly created database using dxpy method\n",
    "    db_uri = dxpy.find_one_data_object(name=f\"{db_name}\".lower(), classname=\"database\")['id']\n",
    "    # Write hail object\n",
    "    url = f\"dnax://{db_uri}/{hail_obj_name}\"\n",
    "    return url\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define GLOBALS\n",
    "HQC_READ_RERUN=False\n",
    "ARRAY_READ_RERUN=False\n",
    "UNRELATED_PCA_RERUN=False\n",
    "RELATED_PCA_RERUN=False\n",
    "CONCORDANCE_RERUN=False\n",
    "SAMPLE_ANNOT_RERUN=True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Read high quality autosome data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "if HQC_READ_RERUN:\n",
    "    mt = hl.import_plink(\n",
    "        bed='file:///mnt/project/notebooks/wes/sample_qc/high_quality_variants/autosomes/autosome_hqc_pruned.bed',\n",
    "        bim='file:///mnt/project/notebooks/wes/sample_qc/high_quality_variants/autosomes/autosome_hqc_pruned.bim',\n",
    "        fam='file:///mnt/project/notebooks/wes/sample_qc/high_quality_variants/autosomes/autosome_hqc_pruned.fam',\n",
    "        reference_genome=\"GRCh38\"\n",
    "    )\n",
    "\n",
    "    url = save_in_hail_format(mt, \"sample_qc\", \"autosomes_hqc_pruned.mt\", rerun=HQC_READ_RERUN)\n",
    "    mt = hl.read_matrix_table(url)\n",
    "else:\n",
    "    url = get_url(\"sample_qc\", \"autosomes_hqc_pruned.mt\")\n",
    "    mt = hl.read_matrix_table(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "mt.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Read array data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "if ARRAY_READ_RERUN:\n",
    "    array_data_pre = \"file:///mnt/project/notebooks/snp/liftover/ukb_c1-22_GRCh38_full_analysis_set_plus_decoy_hla_merged\"\n",
    "\n",
    "    geno_mt = hl.import_plink(\n",
    "        bed=f'{array_data_pre}.bed',\n",
    "        bim=f'{array_data_pre}.bim',\n",
    "        fam=f'{array_data_pre}.fam',\n",
    "        reference_genome='GRCh38'\n",
    "    )\n",
    "\n",
    "    url = save_in_hail_format(geno_mt, \"sample_qc\", \"array.mt\", rerun=ARRAY_READ_RERUN)\n",
    "    geno_mt = hl.read_matrix_table(url)\n",
    "else:\n",
    "    url = get_url(\"sample_qc\", \"array.mt\")\n",
    "    geno_mt = hl.read_matrix_table(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "geno_mt.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Get relatedness statistics for individuals based on KING estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "relatedness_file = \"file:///mnt/project//notebooks/wes/sample_qc/relatedness/related_exome.tsv\"\n",
    "relatedness_table = hl.import_table(\n",
    "    relatedness_file,\n",
    ")\n",
    "relatedness_table = relatedness_table.key_by(\"s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "mt = mt.annotate_cols(\n",
    "    related=hl.or_else(relatedness_table[mt.s].third_degree, \"False\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Calculate PCA for unrelated individuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "if UNRELATED_PCA_RERUN:\n",
    "    unrelated_mt = mt.filter_cols(mt.related==\"True\", keep=False)\n",
    "    # Compute loadings and allele frequency for reference dataset\n",
    "    eigenvalues, scores, loadings_ht = hl.hwe_normalized_pca(unrelated_mt.GT, k=20, compute_loadings=True)   \n",
    "    unrelated_mt = unrelated_mt.annotate_rows(af=hl.agg.mean(unrelated_mt.GT.n_alt_alleles()) / 2)                \n",
    "    loadings_ht = loadings_ht.annotate(af=unrelated_mt.rows()[loadings_ht.key].af)  \n",
    "\n",
    "    url = save_in_hail_format(loadings_ht, \"sample_qc\", \"unrelated_samples_loadings.ht\", rerun=UNRELATED_PCA_RERUN)\n",
    "    loadings_ht = hl.read_table(url)\n",
    "\n",
    "    url = save_in_hail_format(scores, \"sample_qc\", \"unrelated_samples_scores.ht\", rerun=UNRELATED_PCA_RERUN)\n",
    "    unrelated_pca_ht = hl.read_table(url)\n",
    "\n",
    "else:\n",
    "    url = get_url(\"sample_qc\", \"unrelated_samples_loadings.ht\")\n",
    "    loadings_ht = hl.read_table(url)\n",
    "    \n",
    "    url = get_url(\"sample_qc\", \"unrelated_samples_scores.ht\")\n",
    "    unrelated_pca_ht = hl.read_table(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "unrelated_pca_ht.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Project PCA for related individuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "if RELATED_PCA_RERUN:\n",
    "    related_mt = mt.filter_cols(mt.related==\"True\", keep=True)\n",
    "    # Project new genotypes onto loadings\n",
    "    related_ht = hl.experimental.pc_project(related_mt.GT, loadings_ht.loadings, loadings_ht.af)\n",
    "    url = save_in_hail_format(related_ht, \"sample_qc\", \"related_samples_scores.ht\", rerun=RELATED_PCA_RERUN)\n",
    "    related_pca_ht = hl.read_table(url)\n",
    "\n",
    "else:\n",
    "    url = get_url(\"sample_qc\", \"related_samples_scores.ht\")\n",
    "    related_pca_ht = hl.read_table(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "related_pca_ht.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "pca_ht = unrelated_pca_ht.union(related_pca_ht)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get sex imputations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "url = get_url(\"sample_qc\", \"imputed_sex.ht\")\n",
    "imputed_sex = hl.read_table(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Calculate concordance between exome and array\n",
    "\n",
    "Summary:\n",
    "\n",
    "[[0, 10982378230, 265133751019, 58002191288, 11555617883], [35915807, 60381, 1293830, 1223639, 3991], [61992352350, 188536797, 19407337412, 6822719, 107976], [6540281780, 18154898, 4927111, 1827226779, 786962], [3482473571, 4615467, 98920, 1161281, 270922177]]\n",
    "\n",
    "0.9949861324152116\n",
    "\n",
    "469452 overlap\n",
    "\n",
    "\n",
    "[[0, 11050233119, 271184739424, 59029313047, 11719489922], [24208429, 39640, 932677, 634431, 944], [42348255958, 131819648, 13358936421, 3759103, 41894], [2630485865, 9723962, 2759599, 804378228, 326711], [1438527752, 1929404, 40171, 540897, 107579518]]\n",
    "\n",
    "0.9939029360962955\n",
    "\n",
    "469452 overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "if CONCORDANCE_RERUN:\n",
    "    summary_conc, samples_conc, variants_conc = hl.concordance(mt, geno_mt)\n",
    "    print(summary_conc)\n",
    "    print(summary_conc[3][3]/np.array(summary_conc)[1:, 3].sum())\n",
    "    url = save_in_hail_format(samples_conc, \"sample_qc\", \"sample_concordance.ht\", rerun=CONCORDANCE_RERUN)\n",
    "    samples_conc = hl.read_table(url)\n",
    "else:\n",
    "    url = get_url(\"sample_qc\", \"sample_concordance.ht\")\n",
    "    samples_conc = hl.read_table(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "samples_conc = samples_conc.annotate(\n",
    "    hetz_concordance_array=samples_conc.concordance[3][3]/hl.sum(samples_conc.concordance[3][3:])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get previous sample qc (based on array data) performed by UKB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "geno_sample_qc_file = \"file:///mnt/project/fields/data/sample_qc/sample_qc_info.tsv\"\n",
    "geno_sample_qc_table = hl.import_table(\n",
    "    geno_sample_qc_file,\n",
    ")\n",
    "geno_sample_qc_table = geno_sample_qc_table.key_by(\"sample_names\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mark the following samples\n",
    "\n",
    "1. Duplicates\n",
    "2. Related\n",
    "3. Ratio of heterozygous concordance between array and exomes\n",
    "6. Sex from survey\n",
    "7. Genetic sex from array\n",
    "8. Genetic sex from exomes\n",
    "9. Sex chromosome aneuploidy\n",
    "10. Genetic kinship to other participants\n",
    "11. Outlier for heterozygosity or missingness\n",
    "\n",
    "Note:\n",
    "1. Sample call rate\n",
    "2. Eight SD deviation mean ancestry normalized\n",
    "    - Transition/transversion ratio\n",
    "    - Insertion/Deletion allele ratio\n",
    "    - Heterozygous/homozygous call ratio\n",
    "    - SNV/indel \n",
    "    - number of singletons\n",
    "\n",
    "Will be marked after all autosomal variants QC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "if SAMPLE_ANNOT_RERUN:\n",
    "    sample_ht = mt.cols()\n",
    "    # add pca info\n",
    "    sample_ht = sample_ht.annotate(\n",
    "        pca=pca_ht[sample_ht.s].scores\n",
    "    )\n",
    "    # duplicate info\n",
    "    sample_ht = sample_ht.annotate(\n",
    "        duplicate=hl.or_else(relatedness_table[sample_ht.s].duplicate_ind, \"False\"),\n",
    "    )\n",
    "    # imputed sex info\n",
    "    sample_ht = sample_ht.join(imputed_sex)\n",
    "    # heterozygote concordance\n",
    "    sample_ht = sample_ht.annotate(\n",
    "        hetz_concordance_array=samples_conc[sample_ht.s].hetz_concordance_array\n",
    "    )\n",
    "    # additional information from array qc\n",
    "    sample_ht = sample_ht.annotate(\n",
    "        sex_chromosome_aneuploidy=geno_sample_qc_table[sample_ht.s].sex_chromosome_aneuploidy,\n",
    "        genetic_kinship_to_other_participants=geno_sample_qc_table[sample_ht.s].genetic_kinship_to_other_participants,\n",
    "        out_hetz_missing=geno_sample_qc_table[sample_ht.s].out_hetz_missing\n",
    "    )\n",
    "    fields_to_drop = [\"fam_id\", \"pat_id\", \"mat_id\", \"is_female\", \"is_case\", \"is_female_1\"]\n",
    "    sample_ht = sample_ht.drop(*fields_to_drop)\n",
    "    url = save_in_hail_format(sample_ht, \"sample_qc\", \"sample_annot.ht\", rerun=SAMPLE_ANNOT_RERUN)\n",
    "    sample_ht = hl.read_table(url)\n",
    "    \n",
    "else:\n",
    "    url = get_url(\"sample_qc\", \"sample_annot.ht\")\n",
    "    sample_ht = hl.read_table(url)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "hl.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
